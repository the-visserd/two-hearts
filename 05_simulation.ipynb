{"cells":[{"cell_type":"code","execution_count":null,"id":"rXVvOUeMf1Qi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37534,"status":"ok","timestamp":1656053821388,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"rXVvOUeMf1Qi","outputId":"be52d858-9e81-483f-e07e-af2ca77325e4"},"outputs":[],"source":["# For Google Colab / local machine\n","if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive\n","    drive.mount('/content/drive/')\n","    colab_path = \"/content/drive/MyDrive/Masterarbeit/Code/two-hearts/\"\n","    import sys\n","    sys.path.append(colab_path)\n","else:\n","    print('Not running on CoLab')\n","    colab_path = \"\""]},{"cell_type":"code","execution_count":null,"id":"72de0e34","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3484,"status":"ok","timestamp":1656053828177,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"72de0e34","outputId":"78d908aa-a5f7-4f5d-d903-df565e1515cb"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Load NeuroKit and other useful packages\n","import os\n","from copy import deepcopy\n","#!pip install neurokit2\n","import neurokit2 as nk\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as st\n","import scipy.signal as signal\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = [10, 6]  # Bigger images\n","\n","# Load lists\n","from lists import dyads, num_dyads, participants, num_participants\n","\n","# Create list for indices with partners that did not\n","# take part in the experiment together\n","# with an equal gender distribution, e.g.:\n","# 0 1 2 3 4 5 6 7\n","# ->\n","# 0 3 4 7\n","sync_idx = sorted(\n","    [*participants[::4],\n","     *participants[3::4]])"]},{"cell_type":"code","execution_count":1,"id":"e543b1dc","metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1656053836148,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"e543b1dc"},"outputs":[],"source":["from functions import cosine, rpeaks_cosine_interpolation"]},{"cell_type":"code","execution_count":null,"id":"32863df6","metadata":{"executionInfo":{"elapsed":581,"status":"ok","timestamp":1656053841829,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"32863df6"},"outputs":[],"source":["# Make some noise\n","# discrete normal distribution\n","\n","def make_noise(rpeaks_idx, noise_spread=10):\n","    \"\"\"Generates n = rpeaks_idx discrete normal distribution with a sum of 0 and a standard deviation of noise_spread.\\n\n","        As there is no deterministic way to determine these values a while-loop is incoorperated. \n","        The higher noise_spread, the more time it takes.\\n\n","        Returns a nested list with n numbers of noise and percentage of noise based on the mean IBI value.\n","\n","    Args:\n","        rpeaks_idx (array): n & mean IBI\n","        noise_spread (int, optional): standard deviation of noise. Defaults to 10.\n","\n","    Returns:\n","        [noise, noise_percentage] : nested list\n","    \"\"\"\n","    num_rpeaks = len(rpeaks_idx)\n","    noise_size = num_rpeaks-2\n","    # num_rpeaks-2, \n","    # because the first r-peak index does not represent an IBI\n","    # and the noise should end at the last original IBI\n","\n","    noise = np.round(\n","        np.random.normal(\n","            scale=noise_spread, \n","            size=noise_size))\n","    # Search for sum = 0\n","    while \\\n","        sum(noise) != 0 or \\\n","        np.round(np.std(noise), 1) != noise_spread:\n","        noise = np.round(\n","            np.random.normal(\n","                scale=noise_spread, \n","                size=noise_size))\n","    # Convert to ints\n","    noise = [round(x) for x in noise]\n","    noise.insert(0, 0)\n","    noise.append(0)\n","    \n","    # Calculate average noise (%)\n","    # Get IBI\n","    ibi = [\n","        rpeaks_idx[s]-rpeaks_idx[s-1]\n","        for s in range(num_rpeaks)\n","        if s > 0\n","    ]\n","    \n","    ibi_mean = np.mean(np.array(ibi))\n","    noise_percentage = np.mean(abs(np.array(noise)))/ibi_mean*100\n","    noise_percentage = np.round(noise_percentage, 2)\n","    \n","    return [noise, noise_percentage]"]},{"cell_type":"markdown","id":"bb03b92f","metadata":{"id":"bb03b92f"},"source":["# Preprocess data"]},{"cell_type":"code","execution_count":null,"id":"7b512e4f","metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1656053843954,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"7b512e4f"},"outputs":[],"source":["sampling_rate = 2000\n","length = 5*60*sampling_rate\n","\n","ecg_raw = {}\n","ecg = {}\n","rpeaks = {}\n","rpeaks_idx = {}\n","noise = []\n","con = \"gaze\""]},{"cell_type":"code","execution_count":null,"id":"d65084ee","metadata":{"executionInfo":{"elapsed":4113,"status":"ok","timestamp":1656053888362,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"d65084ee"},"outputs":[],"source":["# Prepeare original sample date based on con (SIT or GAZE)\n","\n","# Load data: raw ecgs for 300 s at 2000 Hz\n","ecg_raw[con] = np.load(f\"{colab_path}data/ecg_raw/ecg_raw_{con}.npy\")\n","\n","# Clean and normalize data\n","ecg[con] = [\n","    nk.ecg_clean(\n","        ecg_raw[con][i], \n","        sampling_rate=sampling_rate, \n","        method=\"neurokit\")\n","    for i in participants\n","]\n","# Get R-peaks as a binary time series\n","rpeaks[con] = [\n","    nk.ecg_peaks(\n","        ecg[con][i], \n","        sampling_rate=sampling_rate\n","        )[0][\"ECG_R_Peaks\"]\n","    for i in participants\n","]\n","rpeaks_idx[con] = [\n","    [\n","        s for s, \n","        x in enumerate(rpeaks[con][i]) \n","        if x == 1\n","    ]\n","    for i in participants\n","]\n"]},{"cell_type":"code","execution_count":null,"id":"85f3e8b4","metadata":{"id":"85f3e8b4"},"outputs":[],"source":["# Create SYNC with lag and different levels of noise based on sample data\n","\n","noise_spread = [0,5,10]\n","noise = {}\n","noise_added = {}\n","\n","\n","for x in noise_spread:\n","    noise[x] = [\n","        # returns 2 vaules in a nested list: noise vaules @ [0] & noise percentage @ [1]\n","        make_noise(rpeaks_idx[con][i],noise_spread=x)\n","        for i in participants\n","    ]\n","\n","    rpeaks_idx[\"sync_temp\"] = [\n","        np.array(rpeaks_idx[\"gaze\"][i])+(noise[x][i][0])\n","        for i in participants\n","    ]\n","\n","    rpeaks_idx[f\"sync_{x}\"] = [None]*(len(participants))\n","    rpeaks_idx[f\"sync_{x}\"][::2] = [\n","        rpeaks_idx[\"gaze\"][idx]\n","        for idx in sync_idx\n","    ]\n","    rpeaks_idx[f\"sync_{x}\"][1::2] = [\n","        rpeaks_idx[\"sync_temp\"][idx]\n","        for idx in sync_idx\n","    ]\n","\n","    del rpeaks_idx[\"sync_temp\"]\n","\n","    # Add lag\n","    lag = 1*sampling_rate # 1 sec\n","    rpeaks_idx[f\"sync_{x}\"][1::2] = [\n","        rpeaks_idx[f\"sync_{x}\"][i]+np.array(lag)\n","        for i in participants\n","        if i % 2 == 1\n","    ]\n","    \n","    # Show noise\n","    noise_added[x] = [\n","        noise[x][idx][1]\n","        for idx in sync_idx\n","    ]\n","\n","    print(f\"### Noise spread: {x} ###\")\n","    print(\n","        f\"Noise added:{noise_added[x]} %\\\n","        \\nMean: {np.mean(noise_added[x]):.2f} %\\\n","        \\nSD: {np.std(noise_added[x]):.2f}\\n\")"]},{"cell_type":"code","execution_count":null,"id":"31207c9f","metadata":{"executionInfo":{"elapsed":1063,"status":"aborted","timestamp":1656053714831,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"31207c9f"},"outputs":[],"source":["conditions = [f\"sync_{x}\" for x in noise_spread]\n","length = len(rpeaks[\"gaze\"][0])\n","\n","data_simul_temp = {}\n","for con in conditions:\n","    data_simul_temp[con] = [\n","        rpeaks_cosine_interpolation(\n","            rpeaks_idx[con][i],\n","            length+lag)  # add lag to length of time series\n","        for i in participants\n","    ]\n","\n","    # Cut length of time series back to 600.000\n","    for j in [0, 1]:\n","        data_simul_temp[con][j::2] = [\n","            data_simul_temp[con][i][:-lag]\n","            for i in participants\n","            if i % 2 == j\n","        ]"]},{"cell_type":"code","execution_count":null,"id":"c3b9b898","metadata":{"executionInfo":{"elapsed":1063,"status":"aborted","timestamp":1656053714832,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"c3b9b898"},"outputs":[],"source":["plt.plot(data_simul_temp[\"sync_0\"][0])\n","plt.plot(data_simul_temp[\"sync_0\"][1])\n","plt.xlim(0,9000)"]},{"cell_type":"code","execution_count":null,"id":"5204dc71","metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1656053714833,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"5204dc71"},"outputs":[],"source":["# Trimming & dDownsampling to 50 Hz\n","sampling_rate_new = 50\n","data_trim = {}\n","data_down = {}\n","\n","for con in conditions:\n","    # Trim data_mix to get rid of nans\n","    data_trim[con] = [\n","        # remove first and last 6 s (extra long because of lag)\n","        data_simul_temp[con][i][6*sampling_rate:-6*sampling_rate]\n","        for i in participants\n","    ]\n","    data_down[con] = [\n","        data_trim[con][i][::40]\n","        for i in participants\n","    ]\n","    \n","data = deepcopy(data_down)\n","for con in conditions:\n","    np.save(f\"data/simulation/data_{con}.npy\", data[con])\n"]},{"cell_type":"code","execution_count":null,"id":"1e70e040","metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1656053714833,"user":{"displayName":"Thou Mightst","userId":"08013796147118011125"},"user_tz":-120},"id":"1e70e040"},"outputs":[],"source":["# Sanity check\n","# Should be all equal and true if noise_spread = 0\n","lag_new = 1*sampling_rate_new\n","a = data\n","plt.xlim(10000,10500)\n","plt.plot(a[\"sync_0\"][0])\n","plt.plot(a[\"sync_0\"][1][lag_new:])\n","\n","print(np.equal(a[\"sync_0\"][0][:-lag_new],a[\"sync_0\"][1][lag_new:]))"]},{"cell_type":"markdown","id":"6791f6ac","metadata":{},"source":["### Deep Learning"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"05_simulation copy.ipynb","provenance":[]},"gpuClass":"standard","interpreter":{"hash":"5099852c2ea48d7e79043292bac7dc904323fda34ba4586c42431fdffdc130dd"},"kernelspec":{"display_name":"Python 3.9.12 ('two-hearts')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
