{"cells":[{"cell_type":"markdown","metadata":{"id":"qIERnt9pC-yz"},"source":["# Questioning the Effect of Physiological Heartbeat Synchrony in Romantic Dyads. A Preregistered Deep Learning Analysis."]},{"cell_type":"markdown","metadata":{"id":"nmOgdmJyC-y1"},"source":["### For Google Colab only:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1999,"status":"ok","timestamp":1647875478702,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"2raDtkxkC-y2","outputId":"df4286c7-9ebb-4e2d-dc06-499ef2cd04ee"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Masterarbeit/Code/two-hearts/')"]},{"cell_type":"markdown","metadata":{"id":"iYhFodT5C-y_"},"source":["## Deep Learning"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1647875481121,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"JXC8BydxC-zA","outputId":"a956b48f-7295-43ab-e17d-8e12909ba290"},"outputs":[{"data":{"text/plain":["'2.3.0'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from numpy import array, hstack\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import RepeatVector\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Dropout\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False\n","\n","from lists import list_str\n","\n","tf.version.VERSION"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1647875484043,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"wwQ5kW1a8tYP","outputId":"53f0fa41-960c-416c-e8d4-84cbbde1a5d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["float32\n","(4, 14800)\n"]}],"source":["# Load data\n","data = np.load(\"data/data_gaze.npy\")\n","    # data[i] = np.load(datafiles_google[i]) # for google colab\n","\n","# Data preperation for keras\n","print(data.dtype)\n","print(data.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sampling rate: 50\n"]}],"source":["# Setting sampling rate\n","sampling_rate = 50\n","print(\"Sampling rate:\", sampling_rate)\n","\n","# split a multivariate sequence into samples\n","def split_sequences(sequences, n_steps_in, n_steps_out):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        # to remove redundancy in ECG data ## maybe only use a fraction of sampling_rate to just reduce the redundancy\n","        if i % (sampling_rate) == 0:\n","            # find the end of this pattern\n","            end_ix = i + n_steps_in\n","            out_end_ix = end_ix + n_steps_out\n","            # check if we are beyond the dataset\n","            if out_end_ix > len(sequences):\n","                break\n","            # gather input and output parts of the pattern\n","            seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n","            X.append(seq_x)\n","            y.append(seq_y)\n","    return array(X), array(y)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":855,"status":"ok","timestamp":1647875486578,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"hd0nAx_FC-zF","outputId":"ba41b11c-b46e-4cc1-fd56-29f1bed6b318"},"outputs":[{"ename":"NameError","evalue":"name 'sampling_rate' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20196/1626686846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# choose a number of time steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn_steps_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_vali\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vali\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'sampling_rate' is not defined"]}],"source":["# choose a number of time steps\n","n_steps_in, n_steps_out = 6*sampling_rate, 3*sampling_rate\n","\n","X_train, X_vali, X_test = np.empty((0, n_steps_in, 2))\n","y_train, y_vali, y_test = np.empty((0, n_steps_out, 2))\n","\n","idx = list(range(len(list_str)))[::2] # for dyads\n","\n","for i in range(len(idx)):\n","        # define input sequence\n","        in_seq1 = data[idx[i]]\n","        in_seq2 = data[idx[i]+1]\n","        # convert to [rows, columns] structure\n","        in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n","        in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n","        # horizontally stack columns\n","        dataset = hstack((in_seq1, in_seq2))\n","\n","        # covert into input/output\n","        X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n","\n","        # Data split\n","        num_train_samples = int(0.5 * len(X))\n","        num_val_samples = int(0.25 * len(X))\n","        num_test_samples = len(X) - num_train_samples - num_val_samples\n","        print(\"num_train_samples:\", num_train_samples)\n","        print(\"num_val_samples:\", num_val_samples)\n","        print(\"num_test_samples:\", num_test_samples)\n","\n","        X_train = np.append(X_train,X[:num_train_samples],axis=0)\n","        y_train = np.append(y_train,y[:num_train_samples],axis=0)\n","        X_vali = np.append(X_vali,X[num_train_samples:(num_train_samples+num_val_samples)],axis=0)\n","        y_vali = np.append(y_vali,y[num_train_samples:(num_train_samples+num_val_samples)],axis=0)\n","        X_test = np.append(X_test,X[(num_train_samples+num_val_samples):],axis=0)\n","        y_test = np.append(y_test,y[(num_train_samples+num_val_samples):],axis=0)\n","\n","n_features = X.shape[2]\n","\n","test = np.append(X[3,:,0], y[3,:,0])\n","test2 = np.append(X[2,:,0], y[2,:,0])\n","plt.plot(test)\n","plt.plot(test2)\n","print(len(X_train), len(X_vali), len(X_test))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1647,"status":"ok","timestamp":1647876773741,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"9prvQHUyJCUk"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 300)               363600    \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 150, 300)          0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 150, 150)          270600    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 150, 2)            302       \n","=================================================================\n","Total params: 634,502\n","Trainable params: 634,502\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# define model\n","# Model from Brownlee 2018 - Deep Learning for Time Series Forecasting\n","\n","model = Sequential()\n","model.add(LSTM(300, activation='relu', input_shape=(n_steps_in, n_features), return_sequences=False))\n","model.add(RepeatVector(n_steps_out))\n","model.add(LSTM(150, activation='relu', return_sequences=True))\n","model.add(TimeDistributed(Dense(n_features)))\n","\n","model.compile(keras.optimizers.Adam(learning_rate=0.001,clipvalue=0.5), loss='mse', metrics=[\"mae\"])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1661147,"status":"error","timestamp":1647878441254,"user":{"displayName":"Thou Mightst","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08013796147118011125"},"user_tz":-60},"id":"VbkM5EYjC-zG","outputId":"6cbeff09-14c2-4a0c-ef63-eefbea4fe2ad"},"outputs":[],"source":["# fit model\n","history = model.fit(X_train, y_train, epochs=25, batch_size=64, verbose=1, validation_data=(X_vali, y_vali))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":791},"executionInfo":{"elapsed":1347,"status":"ok","timestamp":1644158101343,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":-60},"id":"79wpthm9C-zG","outputId":"097b05bd-7ef3-4dd5-f7a9-48bd017592a2"},"outputs":[],"source":["history_dict = history.history\n","loss_values = history_dict[\"loss\"]\n","val_loss_values = history_dict[\"val_loss\"]\n","epochs = range(1, len(loss_values) + 1)\n","plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n","plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n","plt.title(\"Training and validation loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.clf()\n","mae = history_dict[\"mae\"]\n","val_mae = history_dict[\"val_mae\"]\n","plt.plot(epochs, mae, \"bo\", label=\"Training mae\")\n","plt.plot(epochs, val_mae, \"b\", label=\"Validation mae\")\n","plt.title(\"Training and validation mean absolute error\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Mean absolute error\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7z7i3mwgNd_j"},"outputs":[],"source":["yhat_train = model.predict(X_train,batch_size=10)\n","yhat_test = model.predict(X_test,batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"executionInfo":{"elapsed":6876,"status":"ok","timestamp":1644158118909,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":-60},"id":"jNXUO6pfC-zG","outputId":"82929f14-90cd-404d-8b6f-e4fc433fd86d"},"outputs":[],"source":["# model demonstration\n","trial = 15\n","person = 1\n","\n","# demonstrate training\n","\n","train = np.append(X_train[trial,:,person],yhat_train[trial,:,person])\n","train2 = np.append(X_train[trial,:,person],y_train[trial,:,person])\n","\n","fig = plt.figure(figsize=(8,4), dpi=96)\n","plt.figure(1)\n","plt.plot(train)\n","plt.plot(train2)\n","\n","# demonstrate prediction\n","\n","test = np.append(X_test[trial,:,person],yhat_test[trial,:,person])\n","test2 = np.append(X_test[trial,:,person],y_test[trial,:,person])\n","\n","fig = plt.figure(figsize=(8,4), dpi=96)\n","plt.figure(2)\n","\n","plt.plot(test)\n","plt.plot(test2)\n","# plt.plot(X_train[trial,:,person])\n","# plt.plot(X_train[trial,:,person])\n","# plt.plot(yhat_train[trial,:,person])"]}],"metadata":{"accelerator":"TPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"03b_multivariate_forecast.ipynb","provenance":[{"file_id":"https://github.com/thevizzerd/two-hearts/blob/main/02_2D_two-hearts.ipynb","timestamp":1644170862158}]},"interpreter":{"hash":"140e3961e635afead8b973c7c4d4b2276a9d6240af442eb4cba65cde2b5b46ba"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('two-hearts': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
